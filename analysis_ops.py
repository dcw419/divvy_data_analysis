import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import platform
from prophet import Prophet 
import numpy as np
from scipy.interpolate import make_interp_spline
# ç­›é€‰ç‰¹å®šçš„æ—¶é—´åˆ†æ
# ==========================================
# ğŸ› ï¸ é€šç”¨å·¥å…·å‡½æ•° (Helper Function)
# ==========================================
def filter_data_by_period(df, year=None, month=None):
    """
    é€šç”¨å·¥å…·: æ ¹æ®å¹´ä»½å’Œæœˆä»½ç­›é€‰æ•°æ®
    å‚æ•°:
        year: int (å¯é€‰), e.g., 2026
        month: int (å¯é€‰), e.g., 1
    è¿”å›:
        ç­›é€‰åçš„ DataFrame
    """
    # 1. ç¡®ä¿æ˜¯æ—¶é—´æ ¼å¼ (è¿™æ˜¯æœ€åŸºç¡€çš„é˜²å¾¡æ€§ç¼–ç¨‹)
    if not pd.api.types.is_datetime64_any_dtype(df['started_at']):
        df = df.copy()
        df['started_at'] = pd.to_datetime(df['started_at'])
    
    # 2. æ„å»ºç­›é€‰æ¡ä»¶
    mask = pd.Series([True] * len(df), index=df.index) # é»˜è®¤å…¨é€‰
    
    label = "All Data"
    
    if year:
        mask &= (df['started_at'].dt.year == year)
        label = f"{year}å¹´"
        
    if month:
        mask &= (df['started_at'].dt.month == month)
        label += f"{month}æœˆ"
        
    # 3. æ‰§è¡Œç­›é€‰
    df_filtered = df.loc[mask].copy()
    
    # 4. æ‰“å°æ—¥å¿— (è®©ä½ çŸ¥é“å‘ç”Ÿäº†ä»€ä¹ˆ)
    print(f"\nğŸ” [Data Filter] Target: {label}")
    if len(df_filtered) == 0:
        print(f"   âš ï¸ è­¦å‘Š: è¯¥æ—¶é—´æ®µæ— æ•°æ®ï¼(Rows: 0)")
        print("   âš ï¸ è‡ªåŠ¨å›é€€: ä½¿ç”¨åŸå§‹å…¨é‡æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
        return df # å…œåº•ç­–ç•¥ï¼šå¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿”å›åŸè¡¨ï¼Œé˜²æ­¢åé¢æŠ¥é”™
    else:
        print(f"   âœ… æˆåŠŸé”å®š: {len(df_filtered):,} æ¡è®¢å•")
        return df_filtered
    
# ==========================================
# 0. ä¸­æ–‡æ˜¾ç¤ºé…ç½® & é£æ ¼
# ==========================================
system_name = platform.system()
if system_name == "Windows":
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
elif system_name == "Darwin":
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'Heiti TC']
else:
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei']
plt.rcParams['axes.unicode_minus'] = False

plt.style.use('ggplot')
sns.set_palette("husl")

# ==========================================
# è¾…åŠ©å‡½æ•°ï¼šè‡ªåŠ¨åˆ†ç±»ä¿å­˜ (Helper Function)
# ==========================================
def _save(fig, data, name, output_dir):
    """
    è‡ªåŠ¨å°†å›¾ç‰‡å­˜å…¥ figures æ–‡ä»¶å¤¹ï¼Œæ•°æ®å­˜å…¥ tables æ–‡ä»¶å¤¹
    """
    # 1. è·¯å¾„æ‹¼æ¥
    fig_dir = os.path.join(output_dir, "figures")
    tbl_dir = os.path.join(output_dir, "tables")
    
    # 2. ä¿å­˜å›¾ç‰‡
    if fig:
        save_path = os.path.join(fig_dir, f"{name}.png")
        # ä½¿ç”¨ bbox_inches='tight' é˜²æ­¢æ ‡é¢˜è¢«åˆ‡
        fig.savefig(save_path, dpi=300, bbox_inches='tight', pad_inches=0.1)
        print(f"   ğŸ“ˆ Image saved: figures/{name}.png")
    
    # 3. ä¿å­˜Excel
    if data is not None:
        excel_path = os.path.join(tbl_dir, f"Data_{name}.xlsx")
        data.to_excel(excel_path, index=False)
        print(f"   ğŸ“Š Table saved: tables/Data_{name}.xlsx")

# ==========================================
# ä¸šåŠ¡åˆ†æå‡½æ•°
# ==========================================

def analyze_user_segmentation(df, output_dir):
    print("\n[Analysis 1] User Segmentation...")
    df['day_name'] = df['started_at'].dt.day_name()
    days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    
    stats = df.groupby(['day_name', 'member_casual'], observed=True).size().reset_index(name='ride_count')
    stats['day_name'] = pd.Categorical(stats['day_name'], categories=days_order, ordered=True)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(data=stats, x='day_name', y='ride_count', hue='member_casual', ax=ax)
    ax.set_title('Weekly User Behavior: Member vs Casual (ç”¨æˆ·åˆ†å±‚è¡Œä¸º)')
    
    _save(fig, stats, "01_User_Segmentation", output_dir)

def analyze_tidal_flow(df, output_dir):
    print("\n[Analysis 2] Tidal Flow (7AM-9AM)...")
    morning_df = df[df['started_at'].dt.hour.between(7, 9)]
    
    outflow = morning_df['start_station_name'].value_counts().reset_index()
    outflow.columns = ['station', 'out_count']
    inflow = morning_df['end_station_name'].value_counts().reset_index()
    inflow.columns = ['station', 'in_count']
    
    flow = pd.merge(outflow, inflow, on='station', how='outer').fillna(0)
    flow['net_flow'] = flow['in_count'] - flow['out_count']
    
    top_deficit = flow.sort_values('net_flow').head(10)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.barplot(data=top_deficit, x='net_flow', y='station', palette='Reds_r', ax=ax)
    ax.set_title('Top 10 Deficit Stations (Morning Rush) - ç¼ºè½¦ç«™ç‚¹åˆ†æ')
    ax.axvline(0, color='black')
    
    _save(fig, top_deficit, "02_Tidal_Flow_Deficit", output_dir)

def analyze_asset_efficiency(df, output_dir):
    print("\n[Analysis 3] Asset Efficiency...")
    stats = df.groupby('rideable_type', observed=True).agg(
        Total_Rides=('ride_id', 'count'),
        Avg_Duration=('duration_min', 'mean')
    ).reset_index()
    
    fig, ax1 = plt.subplots(figsize=(10, 6))
    sns.barplot(data=stats, x='rideable_type', y='Total_Rides', ax=ax1, color='skyblue', alpha=0.6)
    ax1.set_ylabel('Ride Volume')
    
    ax2 = ax1.twinx()
    sns.lineplot(data=stats, x='rideable_type', y='Avg_Duration', ax=ax2, color='red', marker='o', linewidth=3)
    ax2.set_ylabel('Avg Duration (min)')
    
    ax1.set_title('Asset Efficiency: Volume vs Duration (èµ„äº§æ•ˆç‡)')
    
    _save(fig, stats, "03_Asset_Efficiency", output_dir)

def analyze_forecast_2026(df, output_dir):
    print("\n[Analysis 4] Forecasting 2026 (Prophet)...")
    
    # 1. Prophet æ•°æ®å‡†å¤‡
    daily_rides = df.groupby(df['started_at'].dt.date).size().reset_index(name='y')
    daily_rides['ds'] = pd.to_datetime(daily_rides['started_at'])
    daily_rides = daily_rides[['ds', 'y']]
    
    # 2. å»ºæ¨¡
    m = Prophet(yearly_seasonality=True, weekly_seasonality=True)
    m.add_country_holidays(country_name='US') 
    m.fit(daily_rides)
    
    # 3. é¢„æµ‹
    future = m.make_future_dataframe(periods=365)
    forecast = m.predict(future)
    
    # 4. å‡†å¤‡ Excel æ•°æ®
    export_df = pd.DataFrame()
    export_df['Date'] = forecast['ds']
    export_df['Day_Name'] = forecast['ds'].dt.day_name()
    export_df['Predicted_Rides'] = forecast['yhat'].round(0)
    export_df['Trend'] = forecast['trend'].round(0)
    
    mask_2026 = export_df['Date'] >= '2026-01-01'
    final_excel = export_df.loc[mask_2026]
    
    # ä¿å­˜æ•°æ® (è°ƒç”¨è¾…åŠ©å‡½æ•°ï¼Œä½†è¿™é‡Œä¸éœ€è¦ä¼ figï¼Œå› ä¸ºProphetå›¾æ¯”è¾ƒç‰¹æ®Š)
    _save(None, final_excel, "04_Forecast_2026", output_dir)

    # 5. ç‰¹æ®Šç»˜å›¾å¤„ç† (Prophet çš„å›¾éœ€è¦å•ç‹¬å¤„ç†ä¿å­˜)
    
    # å›¾ 1: è¶‹åŠ¿å›¾
    fig1 = m.plot(forecast)
    ax1 = fig1.gca()
    ax1.set_title('2026 Demand Forecast (Total Volume) - æ€»é‡é¢„æµ‹', fontsize=16, pad=20)
    ax1.set_xlabel('Date')
    ax1.set_ylabel('Rides')
    
    # æ‰‹åŠ¨ä¿å­˜åˆ° figures æ–‡ä»¶å¤¹
    fig1.savefig(os.path.join(output_dir, "figures", "04_Forecast_Trend.png"), 
                 dpi=300, bbox_inches='tight', pad_inches=0.1)
    print("   ğŸ“ˆ Image saved: figures/04_Forecast_Trend.png")

    # å›¾ 2: æˆåˆ†å›¾
    fig2 = m.plot_components(forecast)
    fig2.suptitle('Forecast Components (æˆåˆ†åˆ†è§£): Trend, Weekly & Yearly', 
                  fontsize=18, fontweight='bold', y=0.98)
    
    # ç»™å­å›¾åŠ ä¸­æ–‡æ ‡é¢˜
    axes = fig2.get_axes()
    for ax in axes:
        y_label = ax.get_ylabel()
        if 'trend' in y_label:
            ax.set_title('1. Long-Term Growth (é•¿æœŸè¶‹åŠ¿)', loc='left', fontsize=12, fontweight='bold')
        elif 'holidays' in y_label:
            ax.set_title('2. Holiday Effects (èŠ‚å‡æ—¥æ•ˆåº”)', loc='left', fontsize=12, fontweight='bold')
        elif 'weekly' in y_label:
            ax.set_title('3. Weekly Pattern (å‘¨åº¦å‘¨æœŸ)', loc='left', fontsize=12, fontweight='bold')
        elif 'yearly' in y_label:
            ax.set_title('4. Yearly Seasonality (å¹´åº¦å­£èŠ‚æ€§)', loc='left', fontsize=12, fontweight='bold')

    # å¸ƒå±€è°ƒæ•´
    fig2.tight_layout(rect=[0, 0, 1, 0.95])
    
    # æ‰‹åŠ¨ä¿å­˜åˆ° figures æ–‡ä»¶å¤¹
    fig2.savefig(os.path.join(output_dir, "figures", "04_Forecast_Components.png"), 
                 dpi=300, bbox_inches='tight', pad_inches=0.1)
    print("   ğŸ“ˆ Image saved: figures/04_Forecast_Components.png")


def analyze_hourly_bimodal(df, output_dir):
    """
    åˆ†æ 5: æ—¥å‡å°æ—¶çº§åŒå³°æ•ˆåº” (Average Hourly Bimodal Pattern)
    é€»è¾‘å‡çº§ï¼šä»â€œå†å²æ€»å’Œâ€æ”¹ä¸ºâ€œæ—¥å‡å•é‡â€ï¼Œæ›´ç¬¦åˆä¸šåŠ¡ç›´è§‰
    """
    print("\n[Analysis 5] Generating Daily Average Hourly Pattern...")
    
    # 1. ç‰¹å¾å·¥ç¨‹
    df['hour'] = df['started_at'].dt.hour
    df['date'] = df['started_at'].dt.date # æ‹¿åˆ°å…·ä½“æ—¥æœŸ (e.g., 2023-01-01)
    df['day_type'] = df['started_at'].dt.dayofweek.apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')
    
    # ==========================================
    # æ ¸å¿ƒä¿®æ”¹ï¼šè®¡ç®—é€»è¾‘å˜äº†ï¼
    # ==========================================
    
    # ç¬¬ä¸€æ­¥ï¼šç®—å‡ºâ€œæ¯ä¸€å¤©ã€æ¯ä¸ªå°æ—¶â€çš„å…·ä½“å•é‡
    # ç»“æœç±»ä¼¼ï¼š
    # 2023-01-01 (Weekend) | 8ç‚¹ | member | 15å•
    # 2023-01-02 (Weekday) | 8ç‚¹ | member | 200å•
    daily_hourly_counts = df.groupby(['date', 'day_type', 'member_casual', 'hour'], observed=True).size().reset_index(name='count')
    
    # ç¬¬äºŒæ­¥ï¼šç®—å‡ºâ€œå¹³å‡å€¼â€
    # ä¹Ÿå°±æ˜¯æŠŠæ‰€æœ‰ Weekday çš„ 8ç‚¹æ•°æ®æ‹¿æ¥æ±‚ Mean
    avg_stats = daily_hourly_counts.groupby(['day_type', 'member_casual', 'hour'], observed=True)['count'].mean().reset_index()
    
    # ==========================================
    # ç»˜å›¾é€»è¾‘ (ä¿æŒå¹³æ»‘æ›²çº¿)
    # ==========================================
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)
    
    # å®šä¹‰ç”»å›¾å‡½æ•° (å¤ç”¨ä¹‹å‰çš„é€»è¾‘ï¼Œåªæ˜¯è¾“å…¥å˜æˆäº†å¹³å‡å€¼)
    def plot_smooth_line(data, ax, title):
        for user_type in ['member', 'casual']:
            subset = data[data['member_casual'] == user_type]
            
            # æ’åºç¡®ä¿ 0-23 é¡ºåºæ­£ç¡®
            subset = subset.sort_values('hour')
            
            x = subset['hour'].values
            y = subset['count'].values # è¿™é‡Œå·²ç»æ˜¯å¹³å‡å€¼äº†
            
            if len(x) > 3: # æ•°æ®ç‚¹å¤Ÿå¤šæ‰åšå¹³æ»‘
                x_new = np.linspace(x.min(), x.max(), 300)
                try:
                    spl = make_interp_spline(x, y, k=3)
                    y_smooth = spl(x_new)
                    y_smooth = y_smooth.clip(min=0)
                    ax.plot(x_new, y_smooth, label=user_type, linewidth=3)
                    ax.fill_between(x_new, y_smooth, alpha=0.2)
                except:
                    ax.plot(x, y, label=user_type, marker='o')
            else:
                ax.plot(x, y, label=user_type, marker='o')

        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.set_xlabel('Hour of Day (0-23)')
        ax.set_ylabel('Average Rides (Daily)') # Yè½´æ ‡ç­¾å˜äº†
        ax.set_xticks(range(0, 24, 2))
        ax.grid(True, alpha=0.3)
        ax.legend()

    plot_smooth_line(avg_stats[avg_stats['day_type'] == 'Weekday'], axes[0], 'Weekday: Avg Commute (å·¥ä½œæ—¥æ—¥å‡)')
    plot_smooth_line(avg_stats[avg_stats['day_type'] == 'Weekend'], axes[1], 'Weekend: Avg Leisure (å‘¨æœ«æ—¥å‡)')
    
    plt.tight_layout()
    
    # ä¿å­˜
    save_path = os.path.join(output_dir, "figures", "05_Hourly_Average_Pattern.png")
    fig.savefig(save_path, dpi=300, bbox_inches='tight')
    
    print(f"   ğŸ“ˆ Image saved: figures/05_Hourly_Average_Pattern.png")
    
    # ä¿å­˜ Excel ä¾›æŸ¥é˜…
    avg_stats.to_excel(os.path.join(output_dir, "tables", "Data_05_Hourly_Average.xlsx"), index=False)
# # def analyze_hourly_bimodal(df, output_dir):
#     """
#     åˆ†æ 5: å°æ—¶çº§åŒå³°æ•ˆåº” (Hourly Bimodal Pattern)
#     ç›®æ ‡: æ­ç¤ºä¸€å¤© 24 å°æ—¶å†…çš„æµé‡è„‰å†²ï¼ŒéªŒè¯â€œé€šå‹¤åŒå³°â€
#     """
#     print("\n[Analysis 5] Hourly Bimodal Pattern...")
    
#     # 1. æ•°æ®ç‰¹å¾å·¥ç¨‹
#     # æå–å°æ—¶ (0-23)
#     df['hour'] = df['started_at'].dt.hour
    
#     # åŒºåˆ† å·¥ä½œæ—¥ vs å‘¨æœ«
#     # dt.dayofweek: 0=Mon, 4=Fri, 5=Sat, 6=Sun
#     df['day_type'] = df['started_at'].dt.dayofweek.apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')
    
#     # 2. èšåˆæ•°æ®
#     # æˆ‘ä»¬éœ€è¦ç®—â€œå¹³å‡æ¯å°æ—¶å•é‡â€ï¼Œä¸ºäº†å¹³æ»‘æ•°æ®ï¼Œæˆ‘ä»¬å…ˆæŒ‰å°æ—¶ç®—æ€»å’Œ
#     hourly_stats = df.groupby(['day_type', 'member_casual', 'hour'], observed=True).size().reset_index(name='ride_count')
    
#     # 3. ç»˜å›¾ (åˆ›å»ºä¸¤ä¸ªå­å›¾ï¼šå·¦è¾¹æ˜¯å·¥ä½œæ—¥ï¼Œå³è¾¹æ˜¯å‘¨æœ«)
#     fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)
    
#     # --- å·¦å›¾ï¼šå·¥ä½œæ—¥ (Weekday) ---
#     sns.lineplot(
#         data=hourly_stats[hourly_stats['day_type'] == 'Weekday'],
#         x='hour', y='ride_count', hue='member_casual',
#         ax=axes[0], linewidth=3, marker='o'
#     )
#     axes[0].set_title('Weekday: Commute Peaks (å·¥ä½œæ—¥ï¼šé€šå‹¤åŒå³°)', fontsize=14, fontweight='bold')
#     axes[0].set_xlabel('Hour of Day (0-23)')
#     axes[0].set_ylabel('Ride Volume')
#     axes[0].set_xticks(range(0, 24, 2)) # æ¯2å°æ—¶æ˜¾ç¤ºä¸€ä¸ªåˆ»åº¦
#     axes[0].grid(True, alpha=0.3)
    
#     # --- å³å›¾ï¼šå‘¨æœ« (Weekend) ---
#     sns.lineplot(
#         data=hourly_stats[hourly_stats['day_type'] == 'Weekend'],
#         x='hour', y='ride_count', hue='member_casual',
#         ax=axes[1], linewidth=3, marker='o'
#     )
#     axes[1].set_title('Weekend: Leisure Curve (å‘¨æœ«ï¼šä¼‘é—²å•å³°)', fontsize=14, fontweight='bold')
#     axes[1].set_xlabel('Hour of Day (0-23)')
#     axes[1].set_xticks(range(0, 24, 2))
#     axes[1].grid(True, alpha=0.3)
    
#     # 4. ä¿å­˜
#     # ä½¿ç”¨ tight_layout é˜²æ­¢é‡å 
#     plt.tight_layout()
    
#     save_path = os.path.join(output_dir, "figures", "05_Hourly_Bimodal_Pattern.png")
#     # å¦‚æœ figures æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œå­˜åˆ° output_dir
#     if not os.path.exists(os.path.dirname(save_path)):
#         save_path = os.path.join(output_dir, "05_Hourly_Bimodal_Pattern.png")
        
#     fig.savefig(save_path, dpi=300, bbox_inches='tight', pad_inches=0.1)
#     print(f"   ğŸ“ˆ Image saved: {save_path}")
    
#     # å¯¼å‡º Excel æ–¹ä¾¿çœ‹å…·ä½“æ•°å€¼
#     excel_path = os.path.join(output_dir, "tables", "Data_05_Hourly_Stats.xlsx")
#     if not os.path.exists(os.path.dirname(excel_path)):
#          excel_path = os.path.join(output_dir, "Data_05_Hourly_Stats.xlsx")
         
#     hourly_stats.to_excel(excel_path, index=False)
#     print(f"   ğŸ“Š Table saved: {excel_path}")



# ==========================================
# ğŸ§  æ ¸å¿ƒç­–ç•¥åˆ†æå‡½æ•°
# ==========================================
def analyze_station_intelligence_strategy(df, output_dir, target_year=2026, target_month=1):
    """
    é«˜çº§ç­–ç•¥åˆ†æ: ç«™ç‚¹ç”»åƒä¸æ™ºèƒ½è°ƒåº¦ç®—æ³• (Station Intelligence)
    ã€ä¿®å¤ç‰ˆã€‘è§£å†³äº† Categorical ç±»å‹æ— æ³• fillna(0) çš„æŠ¥é”™
    """
    # 1. è°ƒç”¨å·¥å…·å‡½æ•°ç­›é€‰æ•°æ®
    df_target = filter_data_by_period(df, year=target_year, month=target_month)
    
    # ==========================================
    # 2. ç‰¹å¾å·¥ç¨‹ (Feature Engineering)
    # ==========================================
    df_target['hour'] = df_target['started_at'].dt.hour
    df_target['is_weekend'] = df_target['started_at'].dt.dayofweek >= 5
    
    # è¿‡æ»¤æ‰æ²¡æœ‰ç«™ç‚¹åç§°çš„â€œå¹½çµè®¢å•â€
    valid_trips = df_target[df_target['start_station_name'].notna() & df_target['end_station_name'].notna()].copy()
    
    # A. è®¡ç®—å‡ºå‘ç‰¹å¾ (Outflow Profile)
    station_stats = valid_trips.groupby('start_station_name', observed=True).agg(
        Total_Outflow=('ride_id', 'count'),
        AM_Peak_Outflow=('hour', lambda x: ((x >= 7) & (x <= 9)).sum()),
        Weekend_Outflow=('is_weekend', 'sum'),
        Avg_Duration=('duration_min', 'mean')
    ).reset_index()
    
    # B. è®¡ç®—åˆ°è¾¾ç‰¹å¾ (Inflow Profile)
    inflow_stats = valid_trips.groupby('end_station_name', observed=True).size().reset_index(name='Total_Inflow')
    
    # ==========================================
    # ğŸš¨ æ ¸å¿ƒä¿®å¤ï¼šç±»å‹è½¬æ¢ (Fixing TypeError)
    # ==========================================
    # åœ¨åˆå¹¶å‰ï¼ŒæŠŠ category ç±»å‹è½¬ä¸º objectï¼Œé˜²æ­¢ fillna(0) æŠ¥é”™
    station_stats['start_station_name'] = station_stats['start_station_name'].astype('object')
    inflow_stats['end_station_name'] = inflow_stats['end_station_name'].astype('object')
    
    # C. åˆå¹¶ç”»åƒè¡¨ (Merge)
    # outer join ä¼šäº§ç”Ÿå¾ˆå¤š NaN
    station_profile = pd.merge(station_stats, inflow_stats, left_on='start_station_name', right_on='end_station_name', how='outer')
    
    # æ™ºèƒ½åˆå¹¶åå­—ï¼šå¦‚æœ start æ˜¯ NaN (åªæœ‰åˆ°è¾¾)ï¼Œå°±å– end çš„åå­—
    station_profile['Station_Name'] = station_profile['start_station_name'].fillna(station_profile['end_station_name'])
    
    # ç°åœ¨å·²ç»æ˜¯ object ç±»å‹äº†ï¼Œå¯ä»¥å®‰å…¨åœ°å¡«å…… 0
    station_profile = station_profile.fillna(0)
    
    # è®¡ç®—æ¯”ä¾‹æŒ‡æ ‡ (åŠ 1é˜²æ­¢é™¤é›¶)
    station_profile['AM_Ratio'] = station_profile['AM_Peak_Outflow'] / (station_profile['Total_Outflow'] + 1)
    station_profile['Weekend_Ratio'] = station_profile['Weekend_Outflow'] / (station_profile['Total_Outflow'] + 1)

    # ==========================================
    # 3. æ ¸å¿ƒç­–ç•¥ï¼šæ ‡ç­¾ä½“ç³»ç”Ÿæˆ (Tagging System)
    # ==========================================
    print("   ğŸ·ï¸  Generating Station Tags (CDP)...")
    
    def get_tags(row):
        tags = []
        # --- æµé‡åˆ†çº§ ---
        # å¦‚æœæ‰€æœ‰ç«™ç‚¹éƒ½æ˜¯0 (æç«¯æƒ…å†µ)ï¼Œåˆ†ä½æ•°è®¡ç®—å¯èƒ½ä¼šæœ‰é—®é¢˜ï¼ŒåŠ ä¸ªä¿æŠ¤
        threshold_hot = station_profile['Total_Outflow'].quantile(0.9)
        if threshold_hot > 0 and row['Total_Outflow'] > threshold_hot: 
            tags.append('ğŸ”¥æ ¸å¿ƒçƒ­ç‚¹')
        elif row['Total_Outflow'] < 5: 
            tags.append('â„ï¸åƒµå°¸ç‚¹')
            
        # --- ä¸šåŠ¡å±æ€§ ---
        if row['AM_Ratio'] > 0.25: tags.append('ğŸ é€šå‹¤-ä½å®…')
        if row['Weekend_Ratio'] > 0.40: tags.append('ğŸŒ³ä¼‘é—²-æ™¯åŒº')
        if row['Avg_Duration'] < 10: tags.append('âš¡ï¸çŸ­é€”åˆšéœ€')
        
        # --- å¼‚å¸¸çŠ¶æ€ ---
        if row['Total_Outflow'] == 0 and row['Total_Inflow'] > 10:
            tags.append('âš ï¸åªè¿›ä¸å‡º(æ·¤ç§¯)')
            
        return ",".join(tags) if tags else "æ™®é€šç«™ç‚¹"

    station_profile['Station_Tags'] = station_profile.apply(get_tags, axis=1)

    # ==========================================
    # 4. æ ¸å¿ƒç®—æ³•ï¼šæ™ºèƒ½è°ƒåº¦æŒ‡ä»¤ (Smart Rebalancing)
    # ==========================================
    station_profile['Net_Flow'] = station_profile['Total_Inflow'] - station_profile['Total_Outflow']
    
    # ğŸ”´ çº¢åŒ…è½¦ç­–ç•¥
    red_packet_list = station_profile[
        (station_profile['Net_Flow'] > 10) & 
        (station_profile['Station_Tags'].str.contains('çƒ­ç‚¹|ä½å®…'))
    ].sort_values('Net_Flow', ascending=False)
    
    # ğŸ”µ è°ƒåº¦è½¦ç­–ç•¥
    truck_dispatch_list = station_profile[
        station_profile['Net_Flow'] < -10
    ].sort_values('Net_Flow', ascending=True)

    # ==========================================
    # 5. ä¿å­˜ç»“æœä¸å¯è§†åŒ–
    # ==========================================
    file_suffix = f"{target_year}{target_month:02d}"
    
    # --- ä¿å­˜ Excel ---
    excel_name = f"07_Strategy_Ops_{file_suffix}.xlsx"
    save_path = os.path.join(output_dir, "tables", excel_name)
    if not os.path.exists(os.path.dirname(save_path)): save_path = os.path.join(output_dir, excel_name)
    
    # åªä¿ç•™å…³é”®åˆ—ï¼Œè®©è¡¨æ ¼æ›´å¹²å‡€
    cols_to_save = ['Station_Name', 'Station_Tags', 'Net_Flow', 'Total_Outflow', 'Total_Inflow', 'AM_Ratio', 'Weekend_Ratio', 'Avg_Duration']
    # ç¡®ä¿åˆ—å­˜åœ¨ (é˜²æ­¢æ”¹åå¤±è´¥ç­‰æ„å¤–)
    cols_final = [c for c in cols_to_save if c in station_profile.columns]
    
    station_profile[cols_final].to_excel(save_path, index=False)
    print(f"   âœ… Strategy Table saved: {save_path}")

    # --- å¯è§†åŒ– ---
# === åœ¨ analyze_station_intelligence_strategy çš„ç”»å›¾éƒ¨åˆ†æ›¿æ¢ä¸ºä»¥ä¸‹ä»£ç  ===
    plt.figure(figsize=(10, 8))
    sns.scatterplot(data=station_profile, x='Total_Outflow', y='Total_Inflow', color='grey', alpha=0.3, s=30)
    
    if not red_packet_list.empty:
        sns.scatterplot(data=red_packet_list.head(20), x='Total_Outflow', y='Total_Inflow', color='red', s=100)
        # ğŸš¨ æ–°å¢ï¼šæ ‡æ³¨æ·¤ç§¯ Top 3 çš„åå­— + å…·ä½“æ·¤ç§¯æ•°é‡
        for idx, row in red_packet_list.head(3).iterrows():
            plt.annotate(f"{row['Station_Name']}\n(æ·¤ç§¯ +{int(row['Net_Flow'])})",
                         xy=(row['Total_Outflow'], row['Total_Inflow']),
                         xytext=(10, 10), textcoords='offset points',
                         fontsize=10, fontweight='bold', color='darkred',
                         bbox=dict(boxstyle="round,pad=0.2", fc="white", ec="red", alpha=0.7))

    if not truck_dispatch_list.empty:
        sns.scatterplot(data=truck_dispatch_list.head(20), x='Total_Outflow', y='Total_Inflow', color='blue', s=100)
        # ğŸš¨ æ–°å¢ï¼šæ ‡æ³¨ç¼ºè½¦ Top 3 çš„åå­— + å…·ä½“ç¼ºå£æ•°é‡
        for idx, row in truck_dispatch_list.head(3).iterrows():
            plt.annotate(f"{row['Station_Name']}\n(ç¼ºå£ {int(row['Net_Flow'])})",
                         xy=(row['Total_Outflow'], row['Total_Inflow']),
                         xytext=(10, -20), textcoords='offset points',
                         fontsize=10, fontweight='bold', color='darkblue',
                         bbox=dict(boxstyle="round,pad=0.2", fc="white", ec="blue", alpha=0.7))

    limit = max(station_profile['Total_Outflow'].max(), station_profile['Total_Inflow'].max()) + 10
    plt.plot([0, limit], [0, limit], '--', color='black', alpha=0.5, label='Perfect Balance (In = Out)')
    # ... å…¶ä»–æ ‡é¢˜å’Œä¿å­˜é€»è¾‘ ...
    
    plt.title(f'Station Intelligence ({target_year}-{target_month}): Supply vs Demand', fontsize=14)
    plt.xlabel('Demand (Outflow)')
    plt.ylabel('Supply (Inflow)')
    plt.legend()
    plt.grid(True, alpha=0.2)
    
    img_name = f"07_Station_Imbalance_{file_suffix}.png"
    img_save_path = os.path.join(output_dir, "figures", img_name)
    if not os.path.exists(os.path.dirname(img_save_path)): img_save_path = os.path.join(output_dir, img_name)
        
    plt.savefig(img_save_path, dpi=300, bbox_inches='tight')
    print(f"   ğŸ“ˆ Chart saved: {img_save_path}")
    
    # --- ç»ˆç«¯è¾“å‡º ---
    print("\n" + "="*50)
    print(f"ğŸ¤– [AI Strategy] {target_year}-{target_month} Operational Directives")
    print("="*50)
    print(f"ğŸ”´ [çº¢åŒ…è½¦] å»ºè®®å¼€å¯æ•°é‡: {len(red_packet_list)} ä¸ªç«™ç‚¹")
    if not red_packet_list.empty:
        top_s = red_packet_list.iloc[0]
        print(f"   Top 1: {top_s['Station_Name']} (ç§¯å‹ +{int(top_s['Net_Flow'])})")
    
    print(f"\nğŸ”µ [è°ƒåº¦è½¦] å»ºè®®è¡¥è´§æ•°é‡: {len(truck_dispatch_list)} ä¸ªç«™ç‚¹")
    if not truck_dispatch_list.empty:
        top_d = truck_dispatch_list.iloc[0]
        print(f"   Top 1: {top_d['Station_Name']} (ç¼ºå£ {int(top_d['Net_Flow'])})")
    print("="*50)

def analyze_winter_strategy(df, output_dir, target_year=2026, target_month=1):
    """
    ç­–ç•¥åˆ†æ: é’ˆå¯¹ç‰¹å®šæœˆä»½ï¼ˆå¦‚å†¬å­£/æ·¡å­£ï¼‰çš„ç²¾ç»†åŒ–è¿è¥åˆ†æ
    é€šç”¨åŒ–æ”¹é€ ï¼šæ”¯æŒä¼ å…¥ä»»æ„å¹´ä»½å’Œæœˆä»½
    """
    # åŠ¨æ€ç”ŸæˆæŠ¥å‘Šæ ‡é¢˜
    report_title = f"{target_year}å¹´{target_month}æœˆ"
    print(f"\n[Strategy Ops] Generating Strategy Report for {report_title}...")

    # 1. è°ƒç”¨é€šç”¨å‡½æ•°ç­›é€‰æ•°æ® (è§£è€¦æ ¸å¿ƒ)
    # è¿™ä¼šå¤ç”¨æˆ‘ä»¬ä¹‹å‰å†™å¥½çš„ç­›é€‰é€»è¾‘ï¼Œå¦‚æœæ•°æ®ä¸å­˜åœ¨ä¼šè‡ªåŠ¨å¤„ç†
    df_target = filter_data_by_period(df, year=target_year, month=target_month)

    # ==========================================
    # åœºæ™¯ A: æ‰¾å‡ºé€‚åˆæ¨ "çŸ­é€”ä¸€å£ä»·" çš„æ•£å®¢
    # ==========================================
    short_trips = df_target[
        (df_target['member_casual'] == 'casual') & 
        (df_target['duration_min'] <= 10)
    ]
    
    opportunity_size = len(short_trips)
    total_casual = len(df_target[df_target['member_casual'] == 'casual'])
    
    print(f"\n1ï¸âƒ£ [å®šä»·ç­–ç•¥] çŸ­é€”æ•£å®¢åˆ†æ ({report_title})")
    if total_casual > 0:
        ratio = opportunity_size / total_casual
        print(f"   - æ•£å®¢æ€»å•é‡: {total_casual:,}")
        print(f"   - 10åˆ†é’Ÿå†…çŸ­é€”å•: {opportunity_size:,} (å æ¯” {ratio:.1%})")
        print(f"   ğŸ’¡ ç­–ç•¥å»ºè®®: é’ˆå¯¹è¿™ {ratio:.1%} çš„åˆšéœ€äººç¾¤ï¼Œæ¨å‡º '10åˆ†é’Ÿ $1' ä¸€å£ä»·ã€‚")
    else:
        print("   âš ï¸ è¯¥æœˆä»½æ²¡æœ‰æ•£å®¢æ•°æ®ï¼Œæ— æ³•è®¡ç®—è½¬åŒ–ç‡ã€‚")

    # ==========================================
    # åœºæ™¯ B: æ‰¾å‡ºé€‚åˆæ¨ "ç”µå•è½¦å‡èˆ±" çš„ç”¨æˆ·
    # ==========================================
    # é€»è¾‘: è¿˜èƒ½åšæŒéª‘ ç»å…¸è½¦ > 15åˆ†é’Ÿ çš„ç”¨æˆ·
    hardcore_users = df_target[
        (df_target['rideable_type'] == 'classic_bike') & 
        (df_target['duration_min'] > 15)
    ]
    
    upsell_pool = len(hardcore_users)
    
    print(f"\n2ï¸âƒ£ [æ¨èç­–ç•¥] ç”µå•è½¦å‡èˆ±æ½œå®¢åˆ†æ")
    print(f"   - é•¿é€”ç»å…¸è½¦ç”¨æˆ·: {upsell_pool:,}")
    print(f"   ğŸ’¡ ç­–ç•¥å»ºè®®: å‘è¿™ {upsell_pool:,} åç”¨æˆ·æ¨é€ 'ç”µå•è½¦ä½“éªŒåˆ¸'ï¼Œä¸»æ‰“çœåŠ›ç—›ç‚¹ã€‚")

    # ==========================================
    # å¯è§†åŒ–: æ—¶é•¿åˆ†å¸ƒå›¾
    # ==========================================
   # === åœ¨ analyze_winter_strategy çš„ç”»å›¾éƒ¨åˆ†æ›¿æ¢ä¸ºä»¥ä¸‹ä»£ç  ===
    plt.figure(figsize=(10, 6))
    
    # ç”»ç›´æ–¹å›¾
    ax = sns.histplot(data=df_target, x='duration_min', hue='member_casual', 
                      element="step", bins=range(0, 60, 2))
    
    plt.title(f'Trip Duration Distribution ({report_title})', fontsize=14, fontweight='bold')
    plt.xlabel('Trip Duration (minutes)')
    plt.ylabel('Ride Volume')
    plt.axvline(10, color='red', linestyle='--', linewidth=2, label='10min Threshold')
    
    # ğŸš¨ æ–°å¢ï¼šè®¡ç®—æ¯”ä¾‹å¹¶æ·»åŠ å¸¦ç®­å¤´çš„é†’ç›®æ–‡æœ¬æ¡†
    if total_casual > 0:
        ratio = opportunity_size / total_casual
        # è·å– Y è½´æœ€å¤§å€¼ï¼Œç”¨æ¥å®šä½æ–‡æœ¬æ¡†çš„é«˜åº¦
        max_y = ax.get_ylim()[1] 
        
        plt.annotate(
            f'â­ æ ¸å¿ƒåˆšéœ€æ´å¯Ÿ:\næ•£å®¢ç¾¤ä½“ä¸­æœ‰ {ratio:.1%} çš„è®¢å•\néª‘è¡Œæ—¶é—´ä¸åˆ° 10 åˆ†é’Ÿ',
            xy=(5, max_y * 0.5),         # ç®­å¤´æŒ‡åˆ°çš„ä½ç½® (X=5åˆ†é’Ÿ, Y=ä¸€åŠé«˜åº¦)
            xytext=(15, max_y * 0.7),    # æ–‡æœ¬æ¡†æ‰€åœ¨ä½ç½® (X=15åˆ†é’Ÿå¤„)
            arrowprops=dict(facecolor='red', shrink=0.05, width=2, headwidth=8),
            fontsize=12, fontweight='bold', color='darkred',
            bbox=dict(boxstyle="round,pad=0.5", fc="#ffeaea", ec="red", lw=1.5, alpha=0.9)
        )
    
    plt.legend()
    # ... ä¿å­˜å›¾è¡¨ ...
    
    # åŠ¨æ€ç”Ÿæˆæ–‡ä»¶å (é˜²æ­¢è¦†ç›–)
    file_suffix = f"{target_year}{target_month:02d}"
    img_name = f"06_Strategy_Duration_{file_suffix}.png"
    
    save_path = os.path.join(output_dir, "figures", img_name)
    # å®¹é”™ï¼šå¦‚æœ figures æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œå­˜åˆ°ä¸Šä¸€çº§
    if not os.path.exists(os.path.dirname(save_path)):
        save_path = os.path.join(output_dir, img_name)
        
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"   ğŸ“ˆ Chart saved: {save_path}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_asset_efficiency_detail(df, output_dir, target_year=2026, target_month=1):
    print(f"\n[Analysis 3] Asset Efficiency ({target_year}-{target_month:02d})...")
    
    # 1. æ ¸å¿ƒæ”¹åŠ¨ï¼šç²¾å‡†é”å®š 2026 å¹´ 1 æœˆçš„æ•°æ®
    if not pd.api.types.is_datetime64_any_dtype(df['started_at']):
        df['started_at'] = pd.to_datetime(df['started_at'])
        
    mask = (df['started_at'].dt.year == target_year) & (df['started_at'].dt.month == target_month)
    df_target = df.loc[mask].copy()
    
    if len(df_target) == 0:
        print(f"   âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ° {target_year}å¹´{target_month}æœˆ çš„æ•°æ®ï¼è‡ªåŠ¨å›é€€ä½¿ç”¨å…¨é‡æ•°æ®ã€‚")
        df_target = df.copy()
    else:
        print(f"   âœ… æˆåŠŸæå– {len(df_target):,} æ¡è®¢å•è¿›è¡Œèµ„äº§åˆ†æã€‚")

    # 2. èšåˆè®¡ç®— (ä½¿ç”¨ç­›é€‰åçš„ df_target)
    stats = df_target.groupby('rideable_type', observed=True).agg(
        Total_Rides=('ride_id', 'count'),
        Avg_Duration=('duration_min', 'mean')
    ).reset_index()
    
    # 3. ç»˜åˆ¶åŒè½´å›¾
    fig, ax1 = plt.subplots(figsize=(10, 6))
    
    # å·¦è½´ï¼šå•é‡ (æŸ±çŠ¶å›¾)
    sns.barplot(data=stats, x='rideable_type', y='Total_Rides', ax=ax1, color='skyblue', alpha=0.8)
    ax1.set_ylabel('Ride Volume (Total Rides)', fontweight='bold')
    
    # å³è½´ï¼šæ—¶é•¿ (æŠ˜çº¿å›¾)
    ax2 = ax1.twinx()
    sns.lineplot(data=stats, x='rideable_type', y='Avg_Duration', ax=ax2, color='red', marker='o', markersize=10, linewidth=3)
    ax2.set_ylabel('Avg Duration (min)', color='red', fontweight='bold')
    ax2.tick_params(axis='y', labelcolor='red')
    
    # åŠ¨æ€æ ‡é¢˜
    ax1.set_title(f'Asset Efficiency: Volume vs Duration ({target_year}-{target_month:02d} èµ„äº§æ•ˆç‡)', fontsize=14, fontweight='bold')
    
    # 4. åŠ¨æ€æ–‡ä»¶åä¿å­˜ (åŠ ä¸Šå¹´æœˆåç¼€ï¼Œé˜²æ­¢è¦†ç›–å†å²å…¨é‡å›¾è¡¨)
    file_suffix = f"{target_year}{target_month:02d}"
    filename = f"03_Asset_Efficiency_{file_suffix}"
    
    
    _save(fig, stats, filename, output_dir)


def analyze_unit_economics_and_margin(df, output_dir, target_year=2026, target_month=1):
    """
    å•†ä¸šé«˜çº§åˆ†æï¼šå•ä½“ç»æµæ¨¡å‹ (UE) ä¸æ¯›åˆ©æµ‹ç®—
    ç›®æ ‡ï¼šè®¡ç®—çœŸå®å®šä»·ä¸‹çš„å•å‡è¥æ”¶ã€å•å‡æˆæœ¬å’Œæœ€ç»ˆæ¯›åˆ©ç‡
    """
    print(f"\n[Analysis - Unit Economics] Running Financial Model ({target_year}-{target_month:02d})...")
    
    # 1. ç­›é€‰æ—¶é—´èŒƒå›´
    if not pd.api.types.is_datetime64_any_dtype(df['started_at']):
        df['started_at'] = pd.to_datetime(df['started_at'])
        
    mask = (df['started_at'].dt.year == target_year) & (df['started_at'].dt.month == target_month)
    df_target = df.loc[mask].copy()
    
    if len(df_target) == 0:
        print("   âš ï¸ æœªæ‰¾åˆ°æŒ‡å®šæœˆä»½æ•°æ®ï¼Œä½¿ç”¨å…¨é‡æ•°æ®è¿›è¡Œè´¢åŠ¡æ¨¡æ‹Ÿã€‚")
        df_target = df.copy()

    # æ¸…æ´—ï¼šè®¡ç®—æ—¶é•¿å¹¶è¿‡æ»¤å¼‚å¸¸å€¼
    df_target['ended_at'] = pd.to_datetime(df_target['ended_at'])
    df_target['duration_min'] = (df_target['ended_at'] - df_target['started_at']).dt.total_seconds() / 60
    df_clean = df_target[(df_target['duration_min'] >= 1) & (df_target['duration_min'] <= 1440)].copy()

    # ==========================================
    # 2. æ„å»ºè´¢åŠ¡æ¨¡å‹ (The Financial Engine)
    # ==========================================
    # --- å®šä»·è§„åˆ™ (Revenue) ---
    base_price = 1.50      # å‰ 15 åˆ†é’Ÿä¸€å£ä»·
    free_minutes = 15      # å…è´¹/èµ·æ­¥æ—¶é•¿
    overtime_rate = 0.50   # è¶…è¿‡ 15 åˆ†é’Ÿåï¼Œæ¯åˆ†é’Ÿçš„è®¡è´¹
    
    # æ ¸å¿ƒå…¬å¼ï¼šè®¡ç®—æ¯å•è¥æ”¶
    df_clean['Revenue'] = np.where(
        df_clean['duration_min'] <= free_minutes,
        base_price,
        base_price + (df_clean['duration_min'] - free_minutes) * overtime_rate
    )
    
    # --- æˆæœ¬è§„åˆ™ (Cost) é¢„ä¼° ---
    # ç»å…¸è½¦ï¼šæŠ˜æ—§ä¸åŸºç¡€ç»´æŠ¤ (è¾ƒä½)
    classic_cost_per_ride = 0.30 
    # ç”µå•è½¦ï¼šæŠ˜æ—§é«˜ + å……ç”µæˆæœ¬ + äººå·¥æ¢ç”µè°ƒåº¦ (æé«˜)
    electric_cost_per_ride = 1.20 
    
    df_clean['Cost'] = np.where(df_clean['rideable_type'] == 'classic_bike', classic_cost_per_ride, electric_cost_per_ride)
    
    # --- æ¯›åˆ©è®¡ç®— (Gross Profit) ---
    df_clean['Gross_Profit'] = df_clean['Revenue'] - df_clean['Cost']

    # ==========================================
    # 3. èšåˆè´¢åŠ¡æŠ¥è¡¨
    # ==========================================
    financial_report = df_clean.groupby('rideable_type').agg(
        Total_Rides=('ride_id', 'count'),
        Avg_Revenue=('Revenue', 'mean'), # å•å‡è¥æ”¶ (ARPU)
        Avg_Cost=('Cost', 'mean'),       # å•å‡æˆæœ¬
        Avg_Profit=('Gross_Profit', 'mean') # å•å‡æ¯›åˆ©
    ).reset_index()
    
    # è®¡ç®—æ•´ä½“æ¯›åˆ©ç‡ (Margin %)
    financial_report['Gross_Margin'] = financial_report['Avg_Profit'] / financial_report['Avg_Revenue']
    
    # æ ¼å¼åŒ–è½¦å‹åç§°å±•ç¤º
    financial_report['Vehicle_Type'] = financial_report['rideable_type'].str.replace('_', ' ').str.title()

    # æ‰“å°æ§åˆ¶å°è´¢åŠ¡æ‘˜è¦
    print("\nğŸ’° [UE æµ‹ç®—ç»“æœ] èµ„äº§å•ä½“ç»æµæ¨¡å‹:")
    print("-" * 50)
    for idx, row in financial_report.iterrows():
        print(f"[{row['Vehicle_Type']}] æ€»å•é‡: {row['Total_Rides']:,}")
        print(f"   - å•å‡è¥æ”¶ (ARPU): ${row['Avg_Revenue']:.2f}")
        print(f"   - å•å‡æˆæœ¬ (Cost): ${row['Avg_Cost']:.2f}")
        print(f"   - å•å‡æ¯›åˆ© (Profit): ${row['Avg_Profit']:.2f} (æ¯›åˆ©ç‡ {row['Gross_Margin']:.1%})")
    print("-" * 50)

    # ==========================================
    # 4. æ•°æ®å¯è§†åŒ–ï¼šå•ä½“ç»æµæ¨¡å‹å¯¹æ¯”å›¾
    # ==========================================
    # ä½¿ç”¨å †å æŸ±çŠ¶å›¾çš„å˜ä½“ï¼Œå±•ç¤º Revenue = Cost + Profit
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # è®¾ç½®æŸ±å­ä½ç½®å’Œå®½åº¦
    x = np.arange(len(financial_report))
    width = 0.4
    
    # ç”»åº•éƒ¨çš„çº¢è‰²æŸ±å­ï¼šä»£è¡¨æˆæœ¬ (Cost)
    bars_cost = ax.bar(x, financial_report['Avg_Cost'], width, label='Avg Cost per Ride (æˆæœ¬)', color='#e74c3c', edgecolor='black')
    
    # ç”»ä¸Šæ–¹çš„ç»¿è‰²æŸ±å­ï¼šä»£è¡¨æ¯›åˆ© (Gross Profit)ï¼Œå †å åœ¨æˆæœ¬ä¹‹ä¸Š
    # bottom å‚æ•°ä½¿å…¶å †å 
    bars_profit = ax.bar(x, financial_report['Avg_Profit'], width, bottom=financial_report['Avg_Cost'], label='Avg Gross Profit (æ¯›åˆ©)', color='#2ecc71', edgecolor='black')

    # æ·»åŠ æ•°å€¼æ ‡ç­¾ (æ¯›åˆ©)
    for i, bar in enumerate(bars_profit):
        profit_val = financial_report['Avg_Profit'].iloc[i]
        margin_pct = financial_report['Gross_Margin'].iloc[i]
        # åœ¨ç»¿è‰²æŸ±å­ä¸­é—´å†™ä¸Šåˆ©æ¶¦é‡‘é¢å’Œåˆ©æ¶¦ç‡
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_y() + bar.get_height()/2,
                f'+${profit_val:.2f}\n({margin_pct:.0%})',
                ha='center', va='center', color='black', fontweight='bold', fontsize=11)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾ (æˆæœ¬)
    for i, bar in enumerate(bars_cost):
        cost_val = financial_report['Avg_Cost'].iloc[i]
        # åœ¨çº¢è‰²æŸ±å­ä¸­é—´å†™ä¸Šæˆæœ¬é‡‘é¢
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height()/2,
                f'-${cost_val:.2f}',
                ha='center', va='center', color='white', fontweight='bold', fontsize=11)
        
    # åœ¨æŸ±å­é¡¶éƒ¨æ ‡å‡ºæ€»è¥æ”¶ (ARPU)
    for i in range(len(financial_report)):
        total_rev = financial_report['Avg_Revenue'].iloc[i]
        ax.text(x[i], total_rev + 0.1, f'Total ARPU: ${total_rev:.2f}', 
                ha='center', va='bottom', color='black', fontweight='bold', fontsize=12)

    # å›¾è¡¨è£…é¥°
    ax.set_ylabel('Amount (USD)', fontweight='bold', fontsize=12)
    ax.set_title(f'Unit Economics: Profitability by Vehicle Type ({target_year}-{target_month:02d})', fontsize=15, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(financial_report['Vehicle_Type'], fontweight='bold', fontsize=12)
    ax.legend(loc='upper right', fontsize=11)
    
    # çªå‡ºç”µå•è½¦æˆæœ¬é«˜æ˜‚çš„å•†ä¸šæ´å¯Ÿæ–‡æœ¬æ¡†
    max_y = financial_report['Avg_Revenue'].max()
    plt.annotate(
        "\nç”µå•è½¦è™½è¥æ”¶èƒ½åŠ›å¼ºï¼Œä½†é«˜æ˜‚çš„æ¢ç”µ/æŠ˜æ—§æˆæœ¬\nä¸¥é‡æŒ¤å‹äº†åˆ©æ¶¦ç©ºé—´ã€‚ç»å…¸è½¦å•å‡æ¯›åˆ©æ›´é«˜ã€‚",
        xy=(1, financial_report['Avg_Revenue'].iloc[1]), # å‡è®¾ç”µå•è½¦åœ¨ç´¢å¼•1
        xytext=(0.5, max_y * 0.8),
        fontsize=11, fontweight='bold', color='darkred',
        bbox=dict(boxstyle="round,pad=0.5", fc="#ffeaea", ec="red", lw=1.5, alpha=0.9)
    )

    # 5. ä¿å­˜å›¾è¡¨
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    file_suffix = f"{target_year}{target_month:02d}"
    save_path = os.path.join(output_dir, f"08_Unit_Economics_Margin_{file_suffix}.png")
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"   ğŸ“ˆ è´¢åŠ¡æµ‹ç®—å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
    
    return financial_report

def analyze_station_kmeans_clustering(df, output_dir, target_year=2026, target_month=1):
    print(f"\n[Analysis - Machine Learning & GIS] Running Station Clustering & Map Generation ({target_year}-{target_month:02d})...")
    
    # 1. è·å–æ•°æ®ä¸æ¸…æ´—
    df_target = filter_data_by_period(df, year=target_year, month=target_month)
    df_clean = df_target[df_target['start_station_name'].notna() & df_target['start_lat'].notna()].copy()
    
    if len(df_clean) == 0:
        print("   âš ï¸ è­¦å‘Šï¼šå½“å‰æ—¶é—´æ®µæ²¡æœ‰æœ‰æ•ˆç«™ç‚¹æ•°æ®ï¼Œèšç±»ç»ˆæ­¢ã€‚")
        return

    # ==========================================
    # 2. ç‰¹å¾å·¥ç¨‹ (åŒæ—¶æå–ç»çº¬åº¦ç”¨äºåœ°å›¾)
    # ==========================================
    df_clean['hour'] = df_clean['started_at'].dt.hour
    df_clean['is_weekend'] = df_clean['started_at'].dt.dayofweek >= 5
    
    # ğŸš¨ æ–°å¢ï¼šåœ¨èšåˆæ—¶ç®—å‡ºè¯¥ç«™ç‚¹çš„å¹³å‡ç»çº¬åº¦
    station_features = df_clean.groupby('start_station_name', observed=True).agg(
        Total_Rides=('ride_id', 'count'),
        Avg_Duration=('duration_min', 'mean'),
        Weekend_Rides=('is_weekend', 'sum'),
        AM_Peak_Rides=('hour', lambda x: ((x >= 7) & (x <= 9)).sum()),
        Lat=('start_lat', 'mean'),  # æå–çº¬åº¦
        Lng=('start_lng', 'mean')   # æå–ç»åº¦
    ).reset_index()
    
    station_features = station_features[station_features['Total_Rides'] >= 15].copy()
    station_features['Weekend_Ratio'] = station_features['Weekend_Rides'] / station_features['Total_Rides']
    station_features['AM_Peak_Ratio'] = station_features['AM_Peak_Rides'] / station_features['Total_Rides']
    
    features = ['Avg_Duration', 'Weekend_Ratio', 'AM_Peak_Ratio']
    X = station_features[features]

    # ==========================================
    # 3. K-Means èšç±»ä¸ä¸šåŠ¡æ‰“æ ‡
    # ==========================================
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    station_features['Cluster'] = kmeans.fit_predict(X_scaled)

    centroids = station_features.groupby('Cluster')[features].mean()
    
    def assign_business_label(cluster_id):
        row = centroids.loc[cluster_id]
        if row['AM_Peak_Ratio'] == centroids['AM_Peak_Ratio'].max():
            return 'ğŸ¢ æ ¸å¿ƒé€šå‹¤ç‚¹ (æ—©é«˜å³°æ½®æ±æå¼º)'
        elif row['Weekend_Ratio'] == centroids['Weekend_Ratio'].max() or row['Avg_Duration'] == centroids['Avg_Duration'].max():
            return 'ğŸŒ³ å‘¨æœ«ä¼‘é—²ç‚¹ (å‘¨æœ«é«˜é¢‘/éª‘è¡Œä¹…)'
        else:
            return 'ğŸ  å‡è¡¡ç”Ÿæ´»åŒº (æ—¥å¸¸æ•£å®¢/å…¨å¤©å€™)'

    station_features['Station_Persona'] = station_features['Cluster'].apply(assign_business_label)

    # ==========================================
    # 4. ç”Ÿæˆ GIS äº¤äº’å¼åœ°å›¾ (Folium)
    # ==========================================
    print("   ğŸ—ºï¸ Generating Interactive Folium Map...")
    
    # åˆ›å»ºåœ°å›¾ï¼Œä¸­å¿ƒç‚¹è®¾ä¸ºæ‰€æœ‰ç«™ç‚¹çš„å¹³å‡ç»çº¬åº¦ (èŠåŠ å“¥)
    m = folium.Map(location=[station_features['Lat'].mean(), station_features['Lng'].mean()], 
                   zoom_start=11, 
                   tiles='CartoDB positron') # ä½¿ç”¨æ¸…çˆ½çš„åº•å›¾é£æ ¼

    # ä¸ºä¸åŒçš„ä¸šåŠ¡ç”»åƒåˆ†é…é¢œè‰²
    color_map = {
        'ğŸ¢ æ ¸å¿ƒé€šå‹¤ç‚¹ (æ—©é«˜å³°æ½®æ±æå¼º)': '#e74c3c', # çº¢è‰²ï¼Œè¡¨ç¤ºæ€¥éœ€æ—©é«˜å³°è°ƒåº¦çš„çƒ­ç‚¹
        'ğŸŒ³ å‘¨æœ«ä¼‘é—²ç‚¹ (å‘¨æœ«é«˜é¢‘/éª‘è¡Œä¹…)': '#2ecc71', # ç»¿è‰²ï¼Œè¡¨ç¤ºå…¬å›­/ä¼‘é—²åŒº
        'ğŸ  å‡è¡¡ç”Ÿæ´»åŒº (æ—¥å¸¸æ•£å®¢/å…¨å¤©å€™)': '#3498db'  # è“è‰²ï¼Œæ™®é€šç”Ÿæ´»åŒº
    }

    # éå†æ¯ä¸ªç«™ç‚¹ï¼Œåœ¨åœ°å›¾ä¸Šæ‰“ç‚¹
    for idx, row in station_features.iterrows():
        # æ ¹æ®å•é‡å¤§å°å†³å®šåœ†åœˆåŠå¾„ï¼ŒåŠ ä¸Š max å’Œ min é˜²æ­¢åœ†åœˆè¿‡å¤§æˆ–è¿‡å°
        radius_size = min(max(row['Total_Rides'] / 50, 3), 15) 
        
        # å¼¹çª—å†…å®¹ (HTMLæ ¼å¼)ï¼Œä¸šåŠ¡äººå‘˜ç‚¹å‡»åœ†ç‚¹å°±èƒ½çœ‹åˆ°å…·ä½“æ•°æ®
        popup_html = f"""
        <div style="width: 200px;">
            <b>{row['start_station_name']}</b><br>
            <hr style="margin: 5px 0;">
            <b>å±æ€§:</b> {row['Station_Persona']}<br>
            <b>æ€»å•é‡:</b> {row['Total_Rides']} å•<br>
            <b>æ—©é«˜å³°å æ¯”:</b> {row['AM_Peak_Ratio']:.1%}<br>
            <b>å‘¨æœ«å æ¯”:</b> {row['Weekend_Ratio']:.1%}
        </div>
        """
        
        folium.CircleMarker(
            location=[row['Lat'], row['Lng']],
            radius=radius_size,
            popup=folium.Popup(popup_html, max_width=250),
            tooltip=row['start_station_name'], # é¼ æ ‡æ‚¬åœæ˜¾ç¤ºç«™å
            color=color_map.get(row['Station_Persona'], 'gray'),
            fill=True,
            fill_color=color_map.get(row['Station_Persona'], 'gray'),
            fill_opacity=0.7
        ).add_to(m)

    # ä¿å­˜åœ°å›¾ä¸º HTML æ–‡ä»¶
    map_dir = os.path.join(output_dir, "maps")
    if not os.path.exists(map_dir):
        os.makedirs(map_dir)
        
    file_suffix = f"{target_year}{target_month:02d}"
    map_path = os.path.join(map_dir, f"09_Station_Map_{file_suffix}.html")
    m.save(map_path)
    print(f"   ğŸ—ºï¸ Interactive Map saved: {map_path}")

    # (ä¿ç•™åŸæœ¬çš„æ•£ç‚¹å›¾å’ŒExcelä¿å­˜é€»è¾‘)
    # ... çœç•¥ç»˜å›¾ä»£ç ï¼Œå’Œä½ ä¹‹å‰çš„ä¸€æ · ...
    _save(None, station_features, f"09_KMeans_Station_Clustering_{file_suffix}", output_dir)
