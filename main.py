import os
import sys
import data_processing
import analysis_ops
import algorithm
# --- 1. è·¯å¾„é…ç½® (Path Configuration) ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
OUTPUT_DIR = os.path.join(BASE_DIR, "outputs")

# å®šä¹‰å­æ–‡ä»¶å¤¹è·¯å¾„
FIGURES_DIR = os.path.join(OUTPUT_DIR, "figures") # æ”¾å›¾ç‰‡
TABLES_DIR = os.path.join(OUTPUT_DIR, "tables")   # æ”¾Excel
CACHE_DIR = os.path.join(OUTPUT_DIR, "cache")     # æ”¾Parquetç¼“å­˜

# ğŸš¨ å¼€å…³ï¼šå¼ºåˆ¶é‡æ–°è¯»å–æ•°æ® (å¦‚æœæ–°å¢äº†ZIPæ–‡ä»¶ï¼Œæ”¹ä¸º True)
FORCE_RELOAD = False
# 2. é…ç½®ç¯å¢ƒä¸æˆæœ¬å¸¸é‡
business_params = {
        'C_e': 6.0,    'C_c': 0.5,    # æ¢ç”µ/è°ƒåº¦è¾¹é™…æˆæœ¬
        'F_e': 2.0,    'F_c': 0.5,    # æŠ˜æ—§æˆæœ¬
        'M_e': 5000,   'M_c': 5000,   # èµ„äº§è§„æ¨¡ä¸Šé™
        'Q_min': 2000                 # SLA æœ€ä½åº•çº¿
    }
def main():
    print("="*50)
    print("ğŸš´ Shared Bike Strategy Analytics Pipeline ğŸš´")
    print("="*50)
    
    # 2. è‡ªåŠ¨åˆ›å»ºæ‰€æœ‰å¿…è¦çš„æ–‡ä»¶å¤¹
    for folder in [OUTPUT_DIR, FIGURES_DIR, TABLES_DIR, CACHE_DIR]:
        if not os.path.exists(folder):
            os.makedirs(folder)
            print(f"ğŸ“‚ Created directory: {folder}")

    # 3. ETL é˜¶æ®µ (Extract, Transform, Load)
    try:
        # æ³¨æ„ï¼šæˆ‘ä»¬å°† CACHE_DIR ä¼ ç»™æ•°æ®å¤„ç†æ¨¡å—ï¼Œè®©å®ƒæŠŠç¼“å­˜å­˜åœ¨ä¸“é—¨çš„åœ°æ–¹
        df_final = data_processing.get_processed_data(DATA_DIR, CACHE_DIR, force_reload=FORCE_RELOAD)
        
        if df_final is None:
            print("âŒ ETL failed. No data returned.")
            return
            
    except Exception as e:
        print(f"âŒ Critical Error during Data Processing: {e}")
        return

    # 4. åˆ†æé˜¶æ®µ (Analytics & Visualization)
    try:
        # æ³¨æ„ï¼šæˆ‘ä»¬å°† OUTPUT_DIR ä¼ è¿›å»ï¼Œå…·ä½“çš„å­æ–‡ä»¶å¤¹ (tables/figures) åœ¨åˆ†ææ¨¡å—å†…éƒ¨æ‹¼æ¥
        # analysis_ops.analyze_user_segmentation(df_final, OUTPUT_DIR)
        # analysis_ops.analyze_tidal_flow(df_final, OUTPUT_DIR)
        # analysis_ops.analyze_asset_efficiency(df_final, OUTPUT_DIR)
        # analysis_ops.analyze_forecast_2026(df_final, OUTPUT_DIR)
        # analysis_ops.analyze_hourly_bimodal(df_final,OUTPUT_DIR,target_year=2026,target_month=1)
        # analysis_ops.analyze_station_intelligence_strategy(
        #     df_final, 
        #     OUTPUT_DIR, 
        #     target_year=2026, 
        #     target_month=1
        # )
        # analysis_ops.analyze_winter_strategy(df_final,OUTPUT_DIR,target_year=2026,target_month=1)
        # analysis_ops.analyze_asset_efficiency_detail(df_final,OUTPUT_DIR,target_year=2026,target_month=1)
        # analysis_ops.analyze_unit_economics_and_margin(df_final,OUTPUT_DIR,target_year=2026,target_month=1)
        # analysis_ops.analyze_station_kmeans_clustering(df_final,OUTPUT_DIR,target_year=2026,target_month=1)
        algorithm.run_pricing_optimization(
        raw_df=df_final, 
        current_weather=-10, 
        current_hour=8, 
        params=business_params)
    except Exception as e:
        import traceback
        traceback.print_exc() # æ‰“å°è¯¦ç»†æŠ¥é”™ä¿¡æ¯
        print(f"âŒ Critical Error during Analysis: {e}")
        return

    print("\n" + "="*50)
    print(f"ğŸ‰ All Done!")
    print(f"ğŸ“Š Excel Reports -> {TABLES_DIR}")
    print(f"ğŸ“ˆ Chart Images  -> {FIGURES_DIR}")
    print("="*50)

if __name__ == "__main__":
    main()

#############################
CLIåç«¯ç‰ˆæœ¬
############################
# import argparse
# import os
# import time
# import analysis_ops  # å¯¼å…¥æˆ‘ä»¬å°è£…å¥½çš„æ ¸å¿ƒä¸šåŠ¡å‡½æ•°åº“

# def main():
#     # 1. åˆå§‹åŒ–å‘½ä»¤è¡Œå‚æ•°è§£æå™¨
#     parser = argparse.ArgumentParser(description="ğŸš² Divvy å…±äº«å•è½¦ç­–ç•¥è¿è¥åˆ†æå¼•æ“ (CLI)")
    
#     # 2. è·¯å¾„é…ç½® (å¯¹æ¥æˆ‘ä»¬ä¹‹å‰å†™çš„é«˜çº§ç¼“å­˜ç®¡é“)
#     parser.add_argument('--data_dir', type=str, default='./data', help='åŸå§‹ zip æ•°æ®å­˜æ”¾ç›®å½•')
#     parser.add_argument('--cache_dir', type=str, default='./cache', help='Parquet ç¼“å­˜æ–‡ä»¶ç›®å½•')
#     parser.add_argument('--outdir', type=str, default='./output', help='å›¾è¡¨ã€åœ°å›¾å’Œæ•°æ®çœ‹æ¿è¾“å‡ºç›®å½•')
    
#     # 3. ä¸šåŠ¡å‚æ•°é…ç½®
#     parser.add_argument('--year', type=int, default=2023, help='è¦åˆ†æçš„ç›®æ ‡å¹´ä»½ (é»˜è®¤: 2023)')
#     parser.add_argument('--month', type=int, default=1, help='è¦åˆ†æçš„ç›®æ ‡æœˆä»½ (é»˜è®¤: 1)')
    
#     # å¸ƒå°”å€¼å¼€å…³ï¼šå¦‚æœå‘½ä»¤è¡Œè¾“å…¥äº† --force_reloadï¼Œåˆ™ä¸º Trueï¼Œå¦åˆ™ä¸º False
#     parser.add_argument('--force_reload', action='store_true', help='æ˜¯å¦è·³è¿‡ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°æ¸…æ´—åŸå§‹æ•°æ®')
    
#     # 4. ä»»åŠ¡é€‰æ‹© (åŠ å…¥äº†ä½ è¦æ±‚çš„ regression å’Œåˆšå†™çš„ kmeans)
#     parser.add_argument('--task', type=str, default='all', 
#                         choices=['all', 'bimodal', 'efficiency', 'imbalance', 'ue', 'kmeans', 'regression'], 
#                         help='é€‰æ‹©è¦æ‰§è¡Œçš„å•ä¸€åˆ†ææ¨¡å— (é»˜è®¤: all)')

#     # 5. è§£æç”¨æˆ·åœ¨ç»ˆç«¯è¾“å…¥çš„å‘½ä»¤
#     args = parser.parse_args()

#     # --- ç»ˆç«¯ UI æ‰“å° ---
#     print("\n" + "="*50)
#     print(f"ğŸš€ å¯åŠ¨ Divvy ç­–ç•¥åˆ†æåç«¯å¼•æ“...")
#     print(f"ğŸ“… ç›®æ ‡æ—¶é—´: {args.year}å¹´ {args.month}æœˆ")
#     print(f"ğŸ¯ æ‰§è¡Œä»»åŠ¡: {args.task.upper()}")
#     print("="*50)

#     # ==========================================
#     # æ ¸å¿ƒä¿®å¤ï¼šè°ƒç”¨ä½ çš„â€œæ™ºèƒ½ç¼“å­˜æ•°æ®ç®¡é“â€ï¼Œè€Œä¸æ˜¯æ­»æ¿åœ°è¯»å•ä¸ª CSV
#     # ==========================================
#     df = analysis_ops.get_processed_data(
#         data_dir=args.data_dir, 
#         cache_dir=args.cache_dir, 
#         force_reload=args.force_reload
#     )
    
#     if df is None or len(df) == 0:
#         print("âŒ è‡´å‘½é”™è¯¯ï¼šæ•°æ®åŠ è½½å¤±è´¥æˆ–æ•°æ®ä¸ºç©ºï¼Œå¼•æ“ç»ˆæ­¢ã€‚")
#         return

#     # ==========================================
#     # ä»»åŠ¡è·¯ç”±åˆ†å‘ (Task Router)
#     # ==========================================
#     start_time = time.time()
    
#     if args.task in ['all', 'bimodal']:
#         # ç”±äºä½ åŸæœ¬çš„ bimodal æ²¡æœ‰åŠ  year/month å‚æ•°ï¼Œè¿™é‡Œä¸ºäº†å…¼å®¹å¯ä»¥å…ˆä¸ä¼ 
#         analysis_ops.analyze_hourly_bimodal(df, args.outdir)
        
#     if args.task in ['all', 'efficiency']:
#         analysis_ops.analyze_asset_efficiency_detail(df, args.outdir, target_year=args.year, target_month=args.month)
        
#     if args.task in ['all', 'imbalance']:
#         analysis_ops.analyze_station_intelligence_strategy(df, args.outdir, target_year=args.year, target_month=args.month)
        
#     if args.task in ['all', 'ue']:
#         analysis_ops.analyze_unit_economics_and_margin(df, args.outdir, target_year=args.year, target_month=args.month)
        
#     if args.task in ['all', 'kmeans']:
#         # è°ƒç”¨åˆšå†™å¥½çš„ K-Means ç«™ç‚¹èšç±»å’Œ Folium åœ°å›¾
#         analysis_ops.analyze_station_kmeans_clustering(df, args.outdir, target_year=args.year, target_month=args.month)
        
#     if args.task in ['regression']:
#         print("\n[Analysis] Running OLS Regression...")
#         print("ğŸ’¡ æç¤ºï¼šè¿™é‡Œéœ€è¦ä½ åœ¨ analysis_ops.py ä¸­è¡¥å……ç»Ÿè®¡å­¦å›å½’ä»£ç ï¼Œç›®å‰ä¸ºå ä½ç¬¦ã€‚")

#     print("\n" + "="*50)
#     print(f"ğŸ‰ å…¨éƒ¨ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼æ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")
#     print(f"ğŸ“‚ äº§å‡ºç‰©å·²ä¿å­˜è‡³: {os.path.abspath(args.outdir)}")
#     print("="*50 + "\n")

# if __name__ == "__main__":
#     main()
